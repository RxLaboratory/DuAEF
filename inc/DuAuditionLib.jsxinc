/*
DuAuditionLib
Library for interchange with Adobe Audition
Copyright (c) 2017-2018 Nicolas Dufresne, Rainbox Productions
https://rainboxprod.coop

__Contributors:__

	Nicolas Dufresne - Lead developer
	Kevin Masson - Developer

__Thanks to:__

	Dan Ebberts - Writing the first IK Expressions
	Eric Epstein - making the IK's work with 3D Layers
	Kevin Schires – Including images in the script
	Matias Poggini – Bezier IK feature
	Eric Epstein - Making the IK's work with 3D Layers
	Assia Chioukh and Quentin Saint-Georges – User Guides composition
	Motion Cafe – Ideas and feedback
	Fous d’anim – Ideas and feedback
	All 258 Duik 15 indiegogo backers for making this libDuik possible!


This file is part of DuAEF.

DuAEF is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

DuAEF is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with DuAEF. If not, see <http://www.gnu.org/licenses/>.
*/
/**
* Audition interchange tools
* @namespace
* @memberof DuAEF
*/
DuAEF.Audition = {};

/**
* Imports a .storyboard file with all boards
* @memberof DuAEF.Audition
* @param {File}		sesxFile		The Audition session XML File to save
* @param {CompItem}	comp			The composition to export
* @param {bool}   	[audioActiveOnly=false]	Wether to export only layers with the audio enabled, or all layers with audio.
* @param {int}  	[sampling=48000]	  	The audio sampling, in Hz.
* @param {int}   	[bits=32]		  	The audio definition, in bits. One of: 16, 24 or 32.
* @param {string}	[channelType='stereo']		The audio chanel type, one of 'mono', 'stereo' or 'fivePointOne'.
* @param {bool}   	[execute=false]			Wether to open the exported session in Audition once export is done.
* @param {bool}   	[transcode=true]		Wether to extract and transcore audio from video files.
*/
DuAEF.Audition.exportComp = function (sesxFile,comp,audioActiveOnly,sampling,bits,channelType,execute,transcode)
{
	if (typeof sesxFile === 'undefined') throw "Needs an export file";
	if (!(sesxFile instanceof File)) throw "Session file is not a valid File object";
	if (typeof comp === 'undefined') throw "Needs a composition to export";
	if (!(comp instanceof CompItem)) throw "Composition is not a valid CompItem";
	if (typeof audioActiveOnly === 'undefined') audioActiveOnly = false;
	if (typeof sampling === 'undefined') sampling = 48000;
	if (typeof bits === 'undefined') bits = 32;
	if (typeof channelType === 'undefined') channelType = 'stereo';
	if (channelType == '') channelType = 'stereo';
	if (typeof execute === 'undefined') execute = false;
	if (typeof transcode === 'undefined') transcode = true;

	//get all layers with audio
	var audioLayers = DuAEF.DuAE.Comp.getAudioLayers(comp,audioActiveOnly);

	//build xml
	var xmlString = '<sesx version="1.4">' +
		'<session appBuild="10.1.0.174" appVersion="10.1" audioChannelType="' + channelType + '" bitDepth="' + bits + '" duration="' + (comp.duration * sampling) + '" sampleRate="' + sampling + '">' +
		'<name>' + sesxFile.name + '</name>' +
		'<tracks/>' +
		'<sessionState ctiPosition="0" smpteStart="0">' +
		'<selectionState selectionDuration="0" selectionStart="0"/>' +
		'<viewState horizontalViewDuration="0" horizontalViewStart="0" trackControlsWidth="0" verticalScrollOffset="0"/>' +
		'<timeFormatState beatsPerBar="4" beatsPerMinute="120" customFrameRate="12" linkToDefaultTimeSettings="true" noteLength="4" subdivisions="16" timeCodeDropFrame="false" timeCodeFrameRate="30" timeCodeNTSC="false" timeFormat="timeFormatDecimal"/>' +
		'<mixingOptionState defaultPanModeLogarithmic="false" panPower="-3"/>' +
		'</sessionState>' +
		'<clipGroups/>' +
		'<properties/>' +
		'</session>' +
		'<files/>' +
		'</sesx>';
	var sesx = new XML(xmlString);

	//create tracks and clips

	// the source files list, to keep only one instance of each file
	var sourceFiles = [];
	// the transcoder
	if (transcode)
	{
		var ffmpeg = new DuFFMpeg('-y -stats');
		var importedFolder = new Folder(sesxFile.parent.absoluteURI + '/Imported Files/');
	}

	//add clips and tracks to xml
	var numTracks = 1;
	for (var i = 0, num = audioLayers.length; i < num ; i++)
	{
		var layer = audioLayers[i];
		var index = layer.index;

		//create a new track for this clip
		var trackChannelType = channelType;
		//in 5.1, tracks are stereo anyway by default in Audition
		if (trackChannelType == 'fivePointOne') trackChannelType = 'stereo';
		var trackx = DuAEF.Audition.createTrack('Track ' + index,10001+i,numTracks,trackChannelType);

		//get the source file
		var sourceItem = layer.source;
		var clipFile = sourceItem.mainSource.file;
		//check if it already exists and gets the id
		var sourceId = -1;
		for (var j = 0;j < sourceFiles.length ; j++)
		{
			var pathCheck = clipFile.absoluteURI;
			if (sourceItem.hasVideo && transcode)
			{
				var name = pathCheck.substring(pathCheck.lastIndexOf('/')+1,pathCheck.lastIndexOf('.')) + "_audio.wav";
				pathCheck = importedFolder.absoluteURI + '/' + name;
			}
			if (sourceFiles[j][0].absoluteURI == pathCheck)
			{
				sourceId = sourceFiles[j][1];
				break;
			}
		}
		//create a source file
		if (sourceId == -1)
		{
			sourceId = i;
			var sourceFile = clipFile;
			if (sourceItem.hasVideo && transcode)
			{
				var name = clipFile.name.substring(0,clipFile.name.lastIndexOf('.')) + "_audio.wav";
				sourceFile = new File(importedFolder.absoluteURI + '/' + name);
				//add source to the transcoding queue
				var input = new DuFFMpegInputModule(clipFile.fsName);
				var codec = 'pcm_f32le';
				if (bits == 16) codec = 'pcm_s16le';
				else if (bits == 24) codec = 'pcm_s24le';
				var output = new DuFFMpegOutputModule(codec,sourceFile.fsName,'-ar ' + sampling + ' -vn');
				var item = new DuFFMpegQueueItem(input,[output]);
				//add the item to the render queue
				ffmpeg.queue.push(item);
			}
			var filex = DuAEF.Audition.createSourceFile(sourceFile,sourceId);
			sesx.files.appendChild(filex);
			sourceFiles.push([sourceFile,sourceId]);
		}

		//create clip
		var clipName = '';
		clipName = DuPath.getBasename(clipFile);
		if (sourceItem.hasVideo) clipName = clipName + '_audio';

		var clipx = DuAEF.Audition.createClip(clipName,sourceId,i,layer,sampling);

		//add track and clipFile
		trackx = trackx.appendChild(clipx[0]);
		sesx.session.tracks = sesx.session.tracks.appendChild(trackx);
		numTracks++;
	}

	//add the master track
	var masterTrackx = DuAEF.Audition.createMasterTrack('Main',10000,numTracks,channelType);
	sesx.session.tracks = sesx.session.tracks.appendChild(masterTrackx);


	//to string with header and doctype
	XML.prettyPrinting = true;
	var xml = '<?xml version="1.0" encoding="UTF-8" standalone="no" ?>\n<!DOCTYPE sesx>\n' + XML(sesx).toString();

	//save file
	if (sesxFile.open('w'))
	{
		sesxFile.write(xml);
		sesxFile.close();
	}

	if (transcode)
	{
		importedFolder.create();
		ffmpeg.launch();
	}
	if (execute) sesxFile.execute();
}

/**
* Creates an XML track for an Audition session
* @memberof DuAEF.Audition
* @param {string}  name	The track name
* @param {int}	 id	  A unique id for this track
* @param {int}	 index   The index of the track
* @param {string}	[channelType='stereo']	The audio chanel type, one of 'mono', 'stereo' or 'fivePointOne'. Default: 'stereo'
* @return {XML}	The track
*/
DuAEF.Audition.createTrack = function (name,id,index,channelType)
{
	if (typeof channelType === 'undefined') channelType = 'stereo';
	if (channelType == '') channelType = 'stereo';

	var xmlString = '<audioTrack automationLaneOpenState="false" id="' + id + '" index="' + index + '" select="true" visible="true">' +
		'<trackParameters trackHeight="134" trackHue="-1" trackMinimized="false">' +
		'<name>' + name + '</name>' +
		'</trackParameters>' +
		'<trackAudioParameters audioChannelType="' + channelType + '" automationMode="1" monitoring="false" recordArmed="false" solo="false" soloSafe="false">' +
		'<trackOutput outputID="10000" type="trackID"/>' +
		'<trackInput inputID="1"/>' +
		'</trackAudioParameters>' +
		'</audioTrack>';
	var trackx = new XML(xmlString);
	return trackx;
}

/**
* Creates an XML source file for an Audition session
* @memberof DuAEF.Audition
* @param {File}	file				The audio file
* @param {int}	 id				  A unique id for this file
* @return {XML}  	The file
*/
DuAEF.Audition.createSourceFile = function (file,id)
{
	var name = file.name.substring(0,file.name.lastIndexOf('.'));

	xmlString = '<file absolutePath="' + file.fsName + '" id="' + id + '" mediaHandler="AmioWav"/>';
	var filex = new XML(xmlString);

	return filex;
}

/**
 * Creates an XML clip for an Audition session
 * @memberof DuAEF.Audition
 * @param {string}  clipName			The clip name
 * @param {int}	 sourceId			The corresponding source file id
 * @param {int}	 id					A unique id for this clip
 * @param {AVLayer}  [layer]			An After Effects layer to get infos
 * @param {int}  [sampling=48000]		The audio sampling, in Hz.
 * @param {float}   [sourceInPoint]	   The audio source in point
 * @param {float}   [sourceOutPoint]	  The audio source out point
 * @param {float}   [startPoint]		  The clip start point in the track
 * @param {float}   [endPoint]			The clip end point in the track
 * @return {XML}  	The clip
 */
DuAEF.Audition.createClip = function (clipName,sourceId,id,layer,sampling,sourceInPoint,sourceOutPoint,startPoint,endPoint)
{
	if (typeof sampling === 'undefined') sampling = 48000;

	var volume = 1;
	var volumeKeyFrames = [];

	if (typeof layer !== 'undefined')
	{
		//gets cue points
		if (typeof startPoint === 'undefined') startPoint = layer.inPoint * sampling;
		if (typeof endPoint === 'undefined') endPoint = layer.outPoint * sampling;
		if (typeof sourceInPoint === 'undefined') sourceInPoint = (layer.inPoint - layer.startTime) * sampling;
		if (typeof sourceOutPoint === 'undefined') sourceOutPoint = (layer.outPoint - layer.startTime) * sampling;

		//get audio levels
		var levels = layer.property('ADBE Audio Group').property('ADBE Audio Levels');
		var val = levels.valueAtTime(0,false);
		val = DuMath.average(val);
		volume = DuAEF.Audition.dBToVolume(val);

		for (var i = 1, num = levels.numKeys; i <= num; i++)
		{
			var t = levels.keyTime(i)*sampling;
			var v = levels.keyValue(i);
			v = DuMath.average(v);
			v = DuAEF.Audition.dBToKeyFrame(v);
			volumeKeyFrames.push([t,v]);
		}
	}

	var xmlString = '<audioClip clipAutoCrossfade="true" crossFadeHeadClipID="-1" crossFadeTailClipID="-1" endPoint="' + endPoint + '" fileID="' + sourceId + '" hue="-1" id="' + id + '" lockedInTime="false" looped="false" name="' + clipName + '" offline="false" select="false" sourceInPoint="' + sourceInPoint + '" sourceOutPoint="' + sourceOutPoint + '" startPoint="' + startPoint + '" zOrder="0">';

	//add volume
	xmlString += '<component componentID="Audition.Fader" id="clipGain" name="volume" powered="true">' +
		'<parameter index="0" name="volume" parameterValue="' + volume + '">';

	//level keyframes
	var numKeyframes = volumeKeyFrames.length;
	if (numKeyframes > 0)
	{
		xmlString += '<parameterKeyframes enableSplines="false">';
		for(var i = 0; i < numKeyframes; i++)
		{
			xmlString += '<parameterKeyframe sampleOffset="' + volumeKeyFrames[i][0] + '" select="false" type="linear" value="' + volumeKeyFrames[i][1] + '"/>';
		}
		xmlString += '</parameterKeyframes>';
	}

	//end volume
	xmlString += '</parameter>' +
		'<parameter index="1" name="static gain" parameterValue="1"/>' +
		'</component>';

	//end clip
	xmlString += '<fadeIn crossFadeLinkType="linkedAsymmetric" endPoint="0" shape="0" startPoint="0" type="cosine"/>' +
		'<fadeOut crossFadeLinkType="linkedAsymmetric" endPoint="' + (endPoint-startPoint) + '" shape="0" startPoint="' + (endPoint-startPoint) + '" type="cosine"/>' +
		'<channelMap>' +
		'<channel index="0" sourceIndex="0"/>' +
		'<channel index="1" sourceIndex="1"/>' +
		'</channelMap>' +
		'</audioClip>';

	var clipx = new XML(xmlString);

	return clipx;
}

/**
 * Creates an XML master track for an Audition session
 * @memberof DuAEF.Audition
 * @param {string}  name		The track name
 * @param {int}	 id	  	A unique id for this track
 * @param {int}	 index   	The index of the track
 * @param {string}	[channelType='stereo']	The audio chanel type, one of 'mono', 'stereo' or 'fivePointOne'. Default: 'stereo'
 * @return {XML}	The track
 */
DuAEF.Audition.createMasterTrack = function (name,id,index,channelType)
{
	if (typeof channelType === 'undefined') channelType = 'stereo';
	if (channelType == '') channelType = 'stereo';

	var xmlString = '<masterTrack automationLaneOpenState="false" id="' + id + '" index="' + index + '" select="false" visible="true">' +
		'<trackParameters trackHeight="134" trackHue="-1" trackMinimized="false">' +
		'<name>' + name + '</name>' +
		'</trackParameters>' +
		'<trackAudioParameters audioChannelType="' + channelType + '" automationMode="1" monitoring="false" recordArmed="false" solo="false" soloSafe="true">' +
		'<trackOutput outputID="1" type="hardwareOutput"/>' +
		'<trackInput inputID="-1"/>' +
		'</trackAudioParameters>' +
		'<editParameter parameterIndex="0" slotIndex="4294967280"/>' +
		'</masterTrack>';
	var trackx = new XML(xmlString);
	return trackx;
}

/**
 * Converts an audio level in dB to a keyframe value used in .sesx files
 * @memberof DuAEF.Audition
 * @param {float}  dB		the level in dB
 * @return {float}	The volume
 */
DuAEF.Audition.dBToKeyFrame = function (dB)
{
	if (dB == 0) return .65;

	//get the absolute value
	var absdB = Math.abs(dB);
	//get the sign, 1 or -1
	var sign = dB/absdB;
	//conversion. The algorithm was obtained by reverse engineering a .sesx file
	//this does not give the exact volume, but it's accurate enough.
	var p = DuMath.log10(1+absdB/11)*92.85;
	//adjustments, and offset to set 0dB to 65%
	//Audition max volume is 100% at 15dB
	p = p*sign;
	p = 65 + p;
	//this gives a percent, we need a ratio
	p = p/100;

	return p;
 }


/**
* Converts an audio level in dB to a volume used in .sesx files
* @memberof DuAEF.Audition
* @param {float}  dB		the level in dB
* @return {float}	The volume
*/
DuAEF.Audition.dBToVolume = function (dB)
{
	//conversion. The algorithm was obtained by reverse engineering a .sesx file
	//this does not give the exact volume, but it's accurate enough.
	p = Math.pow(10,dB/20);
	return p;
}
